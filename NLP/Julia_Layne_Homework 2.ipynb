{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n",
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n",
      "[nltk_data] Downloading package nps_chat to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "nltk.download('genesis')\n",
    "nltk.download('inaugural')\n",
    "nltk.download('nps_chat')\n",
    "nltk.download('webtext')\n",
    "nltk.download('treebank')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.In Python, create a method for scoring the vocabulary size of a text, and normalize the score from 0 to 1. It does not matter what method you use for normalization as long as you explain it in a short paragraph. (Various methods will be discussed in the live session.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Method to get the Vocab Size and normalize the score\n",
    "\n",
    "def n_vocab_size(*arg):\n",
    "    vocab_size = np.array([])\n",
    "    vocab_size_norm = np.array([])\n",
    "    \n",
    "    #### Getting the Vocab Size\n",
    "    \n",
    "    for text in arg:\n",
    "        print(len(set(text)))\n",
    "        vocab_size = np.append(vocab_size,len(set(text)))\n",
    "\n",
    "    #### Normalizing using sklearn preprocessing \n",
    "    vocab_size_norm_sklearn = minmax_scale(vocab_size, feature_range=(0,1), axis=0)\n",
    "    \n",
    "    return(vocab_size,vocab_size_norm_sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19317\n",
      "6833\n",
      "2789\n",
      "9913\n",
      "6066\n",
      "2166\n",
      "12408\n",
      "1108\n",
      "6807\n"
     ]
    }
   ],
   "source": [
    "vocab_size = n_vocab_size(text1,text2,text3,text4,text5,text6,text7,text8,text9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size\n",
      "* 19317.0\n",
      "* 6833.0\n",
      "* 2789.0\n",
      "* 9913.0\n",
      "* 6066.0\n",
      "* 2166.0\n",
      "* 12408.0\n",
      "* 1108.0\n",
      "* 6807.0\n",
      "Normalized Values by using sklearn\n",
      "* 0.9999999999999999\n",
      "* 0.3144049645779559\n",
      "* 0.09231698610577188\n",
      "* 0.48355208962600904\n",
      "* 0.2722829370091713\n",
      "* 0.05810313581196112\n",
      "* 0.6205722444944807\n",
      "* 0.0\n",
      "* 0.3129770992366412\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary Size\", *vocab_size[0],sep='\\n* ')\n",
    "print(\"Normalized Values by using sklearn\", *vocab_size[1],sep='\\n* ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary score is calculated as the number of distinct words in each text passed in. This will give some numeric value to the variation of words within the given text. While a large vocabulary score will not give us any idea on the complexity of the text, it does mean a larger lexicon will be needed to handle the given text.\n",
    "\n",
    "Using the example code provided, I am using the `minmax_scale` sklearn method to normalize. This calculates the distance between the minimum and maximum values and scales data to where it falls within that range. It is then transformed between the passed range (min,max) which we are setting to be between 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.After consulting section 3.2 in chapter 1 of Bird-Klein, create a method for scoring the long-word vocabulary size of a text, and likewise normalize (and explain) the scoring as in step 1 above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_vocab_size(*arg):\n",
    "    vocab_size = np.array([])\n",
    "    vocab_size_norm = np.array([])\n",
    "    \n",
    "    #### Getting the Long Word (over 15 letters) Vocab Size\n",
    "    \n",
    "    for text in arg:\n",
    "        vocabulary = set(text)\n",
    "        long_words = [word for word in vocabulary if len(word) > 15]\n",
    "        vocab_size = np.append(vocab_size,len(long_words))\n",
    "\n",
    "    #### Normalizing using sklearn preprocessing \n",
    "    vocab_size_norm_sklearn = minmax_scale(vocab_size, feature_range=(0,1), axis=0)\n",
    "    \n",
    "    return(vocab_size,vocab_size_norm_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_vocab_sizes = long_vocab_size(text1,text2,text3,text4,text5,text6,text7,text8,text9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Vocabulary Size\n",
      "* 24.0\n",
      "* 4.0\n",
      "* 0.0\n",
      "* 18.0\n",
      "* 84.0\n",
      "* 0.0\n",
      "* 120.0\n",
      "* 0.0\n",
      "* 2.0\n",
      "Normalized Values by using sklearn\n",
      "* 0.2\n",
      "* 0.03333333333333333\n",
      "* 0.0\n",
      "* 0.15\n",
      "* 0.7\n",
      "* 0.0\n",
      "* 1.0\n",
      "* 0.0\n",
      "* 0.016666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Long Vocabulary Size\", *long_vocab_sizes[0],sep='\\n* ')\n",
    "print(\"Normalized Values by using sklearn\", *long_vocab_sizes[1],sep='\\n* ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24.,   4.,   0.,  18.,  84.,   0., 120.,   0.,   2.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_vocab_sizes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using a similar method to vocabulary score. We are taking that same word set we simply counted before and are filtering out any words that are not longer than 15 characters. The same normalization technique is being used to get a comparison among the texts. This is starting to give us more metrics around the difficulty of understanding text. We are using the assumption that longer words are more difficult to understand. A work with a larger number of long words should increase the overall difficulty of the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Now create a “text difficulty score” by combining the lexical diversity score from homework 1, and your normalized score of vocabulary size and long-word vocabulary size, in equal weighting. Explain what you see when this score is applied to same graded texts you used in homework 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Method to get the Vocab Size and normalize the score\n",
    "\n",
    "def vocab_difficulty(*arg):\n",
    "    vocab_difficulty = np.array([])\n",
    "    vocab_difficulty_norm = np.array([])\n",
    "    \n",
    "    #### Getting the vocab size, normalized\n",
    "    vocab_sizes = n_vocab_size(*arg)\n",
    "    normalized_vocab_size = vocab_sizes[1]\n",
    "    #### Getting the length vocab size, normalized\n",
    "    long_vocab_sizes = long_vocab_size(*arg)\n",
    "    normalized_long_vocab_size = long_vocab_sizes[1]\n",
    "    #### Getting the overall difficulty score (normalized size + normalized length size)\n",
    "    for i in range(len(normalized_vocab_size)):\n",
    "        difficulty = normalized_vocab_size[i]*.5 + normalized_long_vocab_size[i]*.5\n",
    "        vocab_difficulty = np.append(vocab_difficulty,difficulty)\n",
    "\n",
    "    #### Normalizing using sklearn preprocessing \n",
    "    vocab_difficulty_norm_sklearn = minmax_scale(vocab_difficulty, feature_range=(0,1), axis=0)\n",
    "    \n",
    "    return(vocab_difficulty,vocab_difficulty_norm_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19317\n",
      "6833\n",
      "2789\n",
      "9913\n",
      "6066\n",
      "2166\n",
      "12408\n",
      "1108\n",
      "6807\n"
     ]
    }
   ],
   "source": [
    "vocab_difficulties = vocab_difficulty(text1,text2,text3,text4,text5,text6,text7,text8,text9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Difficulty Score\n",
      "* 0.6\n",
      "* 0.17386914895564462\n",
      "* 0.04615849305288594\n",
      "* 0.31677604481300453\n",
      "* 0.4861414685045856\n",
      "* 0.02905156790598056\n",
      "* 0.8102861222472404\n",
      "* 0.0\n",
      "* 0.16482188295165393\n",
      "Normalized Values by using sklearn\n",
      "* 0.7404791758446576\n",
      "* 0.21457747353914625\n",
      "* 0.05696567149005389\n",
      "* 0.39094344098410655\n",
      "* 0.5999627232369785\n",
      "* 0.03585346843335931\n",
      "* 1.0\n",
      "* 0.0\n",
      "* 0.2034119534153422\n"
     ]
    }
   ],
   "source": [
    "print(\"Text Difficulty Score\", *vocab_difficulties[0],sep='\\n* ')\n",
    "print(\"Normalized Values by using sklearn\", *vocab_difficulties[1],sep='\\n* ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Vocab Size Score':vocab_size[0], 'Normalized Vocab Size Score':vocab_size[1], \n",
    "    'Long Word Score':long_vocab_sizes[0], 'Normalized Long Word Score':long_vocab_sizes[1],\n",
    "    'Text difficulty':vocab_difficulties[0],'Normalized Text difficulty':vocab_difficulties[1]}\n",
    "\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocab Size Score</th>\n",
       "      <th>Normalized Vocab Size Score</th>\n",
       "      <th>Long Word Score</th>\n",
       "      <th>Normalized Long Word Score</th>\n",
       "      <th>Text difficulty</th>\n",
       "      <th>Normalized Text difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12408.0</td>\n",
       "      <td>0.620572</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19317.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.740479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6066.0</td>\n",
       "      <td>0.272283</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.486141</td>\n",
       "      <td>0.599963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9913.0</td>\n",
       "      <td>0.483552</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.316776</td>\n",
       "      <td>0.390943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6833.0</td>\n",
       "      <td>0.314405</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.173869</td>\n",
       "      <td>0.214577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6807.0</td>\n",
       "      <td>0.312977</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.164822</td>\n",
       "      <td>0.203412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2789.0</td>\n",
       "      <td>0.092317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046158</td>\n",
       "      <td>0.056966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2166.0</td>\n",
       "      <td>0.058103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029052</td>\n",
       "      <td>0.035853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1108.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vocab Size Score  Normalized Vocab Size Score  Long Word Score  \\\n",
       "6           12408.0                     0.620572            120.0   \n",
       "0           19317.0                     1.000000             24.0   \n",
       "4            6066.0                     0.272283             84.0   \n",
       "3            9913.0                     0.483552             18.0   \n",
       "1            6833.0                     0.314405              4.0   \n",
       "8            6807.0                     0.312977              2.0   \n",
       "2            2789.0                     0.092317              0.0   \n",
       "5            2166.0                     0.058103              0.0   \n",
       "7            1108.0                     0.000000              0.0   \n",
       "\n",
       "   Normalized Long Word Score  Text difficulty  Normalized Text difficulty  \n",
       "6                    1.000000         0.810286                    1.000000  \n",
       "0                    0.200000         0.600000                    0.740479  \n",
       "4                    0.700000         0.486141                    0.599963  \n",
       "3                    0.150000         0.316776                    0.390943  \n",
       "1                    0.033333         0.173869                    0.214577  \n",
       "8                    0.016667         0.164822                    0.203412  \n",
       "2                    0.000000         0.046158                    0.056966  \n",
       "5                    0.000000         0.029052                    0.035853  \n",
       "7                    0.000000         0.000000                    0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='Normalized Text difficulty', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the overall difficulty score, we computed the added normalized values of vocabulary size and length. Having no subject matter knowledge on if length or vocabulary size is a 'better' measure of difficulty, we are simply adding the two scores with no weighting. These were then again normalized across the given text input. \n",
    "\n",
    "Based on the outcomes, the top two most difficult text had trade offs between having a larger vocabulary size and having more long words. The top overall score had the largest (1.00 Normalized) number of long words, but was also second (0.6 Normalized) in vocabulary size. The second overall score in comparison had the largest vocabulary size (1.00 Normalized), but had a much smaller word length score (0.2 Normalized). The skew in word length left many 3 texts with a score of zero. There may be a benefit of adding in multiple levels of word lengths (maybe small= >5, medium >10, and large>15) to get a better sense of the overall text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
