{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Homework 4\n",
    "## POS Tagging\n",
    "### Julia Layne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.metrics import distance\n",
    "\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\tRun one of the part-of-speech (POS) taggers available in Python. \n",
    " - a.\tFind the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    " - b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n",
    "\n",
    "#### Long Sentence\n",
    " > \"Within a short walk of Longbourn lived a family with whom the Bennets were particularly intimate.\" - Jane Austen, Pride and Prejudice\n",
    "#### Short Sentence\n",
    " > \"I did not expect such a compliment.\" - Jane Austen, Pride and Prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_and_P_long = 'Within a short walk of Longbourn lived a family with whom the Bennets were particularly intimate.'\n",
    "P_and_P_short = 'I did not expect such a compliment.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_pos_tagger (sentence):\n",
    "    print(sentence)\n",
    "    text = word_tokenize(sentence)\n",
    "    print('Gets tagged into the POS:')\n",
    "    pos = nltk.pos_tag(text)\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a - Long Sentence POS Tagging\n",
      "Within a short walk of Longbourn lived a family with whom the Bennets were particularly intimate.\n",
      "Gets tagged into the POS:\n",
      "[('Within', 'IN'), ('a', 'DT'), ('short', 'JJ'), ('walk', 'NN'), ('of', 'IN'), ('Longbourn', 'NNP'), ('lived', 'VBD'), ('a', 'DT'), ('family', 'NN'), ('with', 'IN'), ('whom', 'WP'), ('the', 'DT'), ('Bennets', 'NNS'), ('were', 'VBD'), ('particularly', 'RB'), ('intimate', 'JJ'), ('.', '.')]\n",
      "\n",
      "b - Short Sentence POS Tagging\n",
      "I did not expect such a compliment.\n",
      "Gets tagged into the POS:\n",
      "[('I', 'PRP'), ('did', 'VBD'), ('not', 'RB'), ('expect', 'VB'), ('such', 'JJ'), ('a', 'DT'), ('compliment', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print('a - Long Sentence POS Tagging')\n",
    "long_pos_nltk = nltk_pos_tagger(P_and_P_long)\n",
    "print(long_pos_nltk)\n",
    "print('\\nb - Short Sentence POS Tagging')\n",
    "short_pos_nltk = nltk_pos_tagger(P_and_P_short)\n",
    "print(short_pos_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    " - a.\tDoes it produce the same or different output?\n",
    " - b.\tExplain any differences as best you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackabuse.com/python-for-nlp-parts-of-speech-tagging-and-named-entity-recognition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Within', 'IN'), ('a', 'DT'), ('short', 'JJ'), ('walk', 'NN'), ('of', 'IN'), ('Longbourn', 'NNP'), ('lived', 'VBD'), ('a', 'DT'), ('family', 'NN'), ('with', 'IN'), ('whom', 'WP'), ('the', 'DT'), ('Bennets', 'NNS'), ('were', 'VBD'), ('particularly', 'RB'), ('intimate', 'JJ'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(str(long_pos_nltk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in c:\\users\\julia\\anaconda3\\lib\\site-packages (1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\julia\\anaconda3\\lib\\site-packages (from stanza) (2.24.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\julia\\anaconda3\\lib\\site-packages (from stanza) (3.14.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from stanza) (1.7.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\julia\\anaconda3\\lib\\site-packages (from stanza) (4.47.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\julia\\anaconda3\\lib\\site-packages (from stanza) (1.18.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests->stanza) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests->stanza) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests->stanza) (3.0.4)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from protobuf->stanza) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\julia\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.7.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 63.7MB/s]                    \n",
      "2021-02-24 19:32:49 INFO: Downloading default packages for language: en (English)...\n",
      "2021-02-24 19:32:49 INFO: File exists: C:\\Users\\julia\\stanza_resources\\en\\default.zip.\n",
      "2021-02-24 19:32:52 INFO: Finished downloading models and saved to C:\\Users\\julia\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza\n",
    "import stanza\n",
    "stanza.download('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanza_pos_tagger (sentence_in,previous_pos):\n",
    "    doc = nlp(sentence_in)\n",
    "    sentence = doc.sentences[0]\n",
    "    data = []\n",
    "    for i in range(len(sentence.words)):\n",
    "        word = sentence.words[i]\n",
    "        data.append([word.text,word.upos,previous_pos[i][1]])\n",
    "        \n",
    "    df = pd.DataFrame(data, columns = ['Word', 'Stanza', 'NLTK'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 19:32:52 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2021-02-24 19:32:52 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "========================\n",
      "\n",
      "2021-02-24 19:32:52 INFO: Use device: cpu\n",
      "2021-02-24 19:32:52 INFO: Loading: tokenize\n",
      "2021-02-24 19:32:52 INFO: Loading: pos\n",
      "2021-02-24 19:32:52 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos')\n",
    "\n",
    "df = stanza_pos_tagger(P_and_P_long,long_pos_nltk)\n",
    "df_short = stanza_pos_tagger(P_and_P_short,short_pos_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "handcoding_sameness = [True, \n",
    "                       True,True,True,True,True,\n",
    "                      True,True,True,True,True,\n",
    "                      True,False,False,True,True,\n",
    "                      True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Match'] = handcoding_sameness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Stanza</th>\n",
       "      <th>NLTK</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Within</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>short</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walk</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Longbourn</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lived</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>family</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>whom</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WP</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bennets</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>were</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>particularly</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>intimate</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word Stanza NLTK  Match\n",
       "0         Within    ADP   IN   True\n",
       "1              a    DET   DT   True\n",
       "2          short    ADJ   JJ   True\n",
       "3           walk   NOUN   NN   True\n",
       "4             of    ADP   IN   True\n",
       "5      Longbourn  PROPN  NNP   True\n",
       "6          lived   VERB  VBD   True\n",
       "7              a    DET   DT   True\n",
       "8         family   NOUN   NN   True\n",
       "9           with    ADP   IN   True\n",
       "10          whom   PRON   WP   True\n",
       "11           the    DET   DT   True\n",
       "12       Bennets  PROPN  NNS  False\n",
       "13          were    AUX  VBD  False\n",
       "14  particularly    ADV   RB   True\n",
       "15      intimate    ADJ   JJ   True\n",
       "16             .  PUNCT    .   True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Stanza</th>\n",
       "      <th>NLTK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>did</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not</td>\n",
       "      <td>PART</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expect</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>such</td>\n",
       "      <td>DET</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>compliment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word Stanza NLTK\n",
       "0           I   PRON  PRP\n",
       "1         did    AUX  VBD\n",
       "2         not   PART   RB\n",
       "3      expect   VERB   VB\n",
       "4        such    DET   JJ\n",
       "5           a    DET   DT\n",
       "6  compliment   NOUN   NN\n",
       "7           .  PUNCT    ."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "handcoding_sameness = [True, \n",
    "                       False,False,True,False,True,\n",
    "                      True,True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Stanza</th>\n",
       "      <th>NLTK</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>did</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not</td>\n",
       "      <td>PART</td>\n",
       "      <td>RB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expect</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>such</td>\n",
       "      <td>DET</td>\n",
       "      <td>JJ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>compliment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word Stanza NLTK  Match\n",
       "0           I   PRON  PRP   True\n",
       "1         did    AUX  VBD  False\n",
       "2         not   PART   RB  False\n",
       "3      expect   VERB   VB   True\n",
       "4        such    DET   JJ  False\n",
       "5           a    DET   DT   True\n",
       "6  compliment   NOUN   NN   True\n",
       "7           .  PUNCT    .   True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short['Match'] = handcoding_sameness\n",
    "df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long had a mismatch rate of 2 out 17:  11.76470588235294 %\n",
      "Short had a mismatch rate of 3 out 8:  37.5 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Long had a mismatch rate of 2 out 17: \",(2/17)*100, \"%\")\n",
    "print(\"Short had a mismatch rate of 3 out 8: \", (3/8)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had expected the longer quote to have more disparity between the two taggers. However, the short quote had a much higher mismatch rate. This is likely because there was less context for the words in the shorter sentence. Also, the shorter sentence had small filler words: 'such' and 'a'. Stanza appeared to struggle with these and the phrase 'did not' modifying expect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tIn a news article from this week’s news, find a random sentence of at least 10 words.\n",
    " - a.\tLooking at the Penn tag set, manually POS tag the sentence yourself.\n",
    " - b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n",
    " - c.\tExplain any differences between the two taggers and your manual tagging as much as you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "news =\"She spent the next several days wandering in the ice, trying to find him.\"\n",
    "handcoded = ['PRP', 'VBD', 'DT', 'JJ', 'JJ', 'NNS', 'VB','IN', 'DT', 'NN', 'SYM','VB', 'TO', 'VB','PRP','SYM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She spent the next several days wandering in the ice, trying to find him.\n",
      "Gets tagged into the POS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Stanza</th>\n",
       "      <th>NLTK</th>\n",
       "      <th>handcoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spent</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>next</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>several</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>days</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wandering</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ice</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>trying</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>find</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>him</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word Stanza NLTK handcoded\n",
       "0         She   PRON  PRP       PRP\n",
       "1       spent   VERB  VBD       VBD\n",
       "2         the    DET   DT        DT\n",
       "3        next    ADJ   JJ        JJ\n",
       "4     several    ADJ   JJ        JJ\n",
       "5        days   NOUN  NNS       NNS\n",
       "6   wandering   VERB  VBG        VB\n",
       "7          in    ADP   IN        IN\n",
       "8         the    DET   DT        DT\n",
       "9         ice   NOUN   NN        NN\n",
       "10          ,  PUNCT    ,       SYM\n",
       "11     trying   VERB  VBG        VB\n",
       "12         to   PART   TO        TO\n",
       "13       find   VERB   VB        VB\n",
       "14        him   PRON  PRP       PRP\n",
       "15          .  PUNCT    .       SYM"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_news = nltk_pos_tagger(news)\n",
    "news_tagged = stanza_pos_tagger(news,nltk_news)\n",
    "news_tagged['handcoded'] = handcoded\n",
    "news_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I missed that wandering was a present participle, but NLTK was able to catch it. Stanza did not, but stanza has a much less robust tagset than the Penn Treebank. In general, I would expect my own manual tags to look more like Stanza's and be more broad. Though I am a native English speaker, it has been 20 years since I diagrammed sentences in school. I can likely get near the true tagging of sentences, but a program like NLTK will almost always beat me on the more specific tags."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
